==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TinyLLM                                  [64, 444, 25000]          --
├─Embedding: 1-1                         [64, 444, 512]            12,800,000
├─ModuleList: 1-2                        --                        --
│    └─TransformerBlock: 2-1             [64, 444, 512]            --
│    │    └─RMSNorm: 3-1                 [64, 444, 512]            512
│    │    └─Attention: 3-2               [64, 444, 512]            786,432
│    │    └─RMSNorm: 3-3                 [64, 444, 512]            512
│    │    └─FeedForward: 3-4             [64, 444, 512]            2,359,296
│    └─TransformerBlock: 2-2             [64, 444, 512]            --
│    │    └─RMSNorm: 3-5                 [64, 444, 512]            512
│    │    └─Attention: 3-6               [64, 444, 512]            786,432
│    │    └─RMSNorm: 3-7                 [64, 444, 512]            512
│    │    └─FeedForward: 3-8             [64, 444, 512]            2,359,296
│    └─TransformerBlock: 2-3             [64, 444, 512]            --
│    │    └─RMSNorm: 3-9                 [64, 444, 512]            512
│    │    └─Attention: 3-10              [64, 444, 512]            786,432
│    │    └─RMSNorm: 3-11                [64, 444, 512]            512
│    │    └─FeedForward: 3-12            [64, 444, 512]            2,359,296
│    └─TransformerBlock: 2-4             [64, 444, 512]            --
│    │    └─RMSNorm: 3-13                [64, 444, 512]            512
│    │    └─Attention: 3-14              [64, 444, 512]            786,432
│    │    └─RMSNorm: 3-15                [64, 444, 512]            512
│    │    └─FeedForward: 3-16            [64, 444, 512]            2,359,296
│    └─TransformerBlock: 2-5             [64, 444, 512]            --
│    │    └─RMSNorm: 3-17                [64, 444, 512]            512
│    │    └─Attention: 3-18              [64, 444, 512]            786,432
│    │    └─RMSNorm: 3-19                [64, 444, 512]            512
│    │    └─FeedForward: 3-20            [64, 444, 512]            2,359,296
│    └─TransformerBlock: 2-6             [64, 444, 512]            --
│    │    └─RMSNorm: 3-21                [64, 444, 512]            512
│    │    └─Attention: 3-22              [64, 444, 512]            786,432
│    │    └─RMSNorm: 3-23                [64, 444, 512]            512
│    │    └─FeedForward: 3-24            [64, 444, 512]            2,359,296
├─RMSNorm: 1-3                           [64, 444, 512]            512
├─Linear: 1-4                            [64, 444, 25000]          12,800,000
==========================================================================================
Total params: 44,481,024
Trainable params: 44,481,024
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 2.85
==========================================================================================
Input size (MB): 12.84
Forward/backward pass size (MB): 14296.20
Params size (MB): 177.92
Estimated Total Size (MB): 14486.97
==========================================================================================